version: "3"

services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env

#  resourcemanager:
#    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
#    container_name: resourcemanager
#    restart: always
#    environment:
#      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
#    env_file:
#      - ./hadoop.env
#
#  nodemanager1:
#    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
#    container_name: nodemanager
#    restart: always
#    environment:
#      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
#    env_file:
#      - ./hadoop.env
#
#  historyserver:
#    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
#    container_name: historyserver
#    restart: always
#    environment:
#      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
#    volumes:
#      - hadoop_historyserver:/hadoop/yarn/timeline
#    env_file:
#      - ./hadoop.env

  zookeeper-1:
    image: confluentinc/cp-zookeeper:7.3.1
    ports:
      - '32181:32181'
      - '2181:2181'
    environment:
      ZOOKEEPER_CLIENT_PORT: 32181
      ZOOKEEPER_TICK_TIME: 2000


  kafka-1:
    image: confluentinc/cp-kafka:7.3.1
    ports:
      - '9092:9092'
    depends_on:
      - zookeeper-1
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:32181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-1:29092,EXTERNAL://localhost:9092
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: 'false'


  kafka-2:
    image: confluentinc/cp-kafka:7.3.1
    ports:
      - '9093:9093'
    depends_on:
      - zookeeper-1
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:32181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-2:29093,EXTERNAL://localhost:9093
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: 'false'


  kafka-3:
    image: confluentinc/cp-kafka:7.3.1
    ports:
      - '9094:9094'
    depends_on:
      - zookeeper-1
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:32181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-3:29094,EXTERNAL://localhost:9094
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: 'false'

  kafdrop:
    image: obsidiandynamics/kafdrop:latest
    #    networks:
    #      - broker-kafka
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
    ports:
      - 19000:9000
    environment:
      KAFKA_BROKERCONNECT: kafka-1:29092

  zoonavigator:
    image:  elkozmon/zoonavigator:latest
    ports:
      - 19001:9000
    environment:
      HTTP_PORT: 9000

  prometheus:
    image: prom/prometheus:v2.47.0
    ports:
      - "19002:9090"
    extra_hosts:
      - "host.docker.internal:host-gateway" #crutial for prometheus to be able to access localhost
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml


  grafana:
    image: grafana/grafana:10.1.0
    ports:
      - "19003:3000"
    environment:
      - "GF_SECURITY_ADMIN_PASSWORD=grafana"

volumes:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver: