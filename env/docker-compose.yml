version: "3"

services:
  #############################################
  #                   HDFS                    #
  #############################################

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env

#  resourcemanager:
#    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
#    container_name: resourcemanager
#    restart: always
#    environment:
#      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
#    env_file:
#      - ./hadoop.env
#
#  nodemanager1:
#    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
#    container_name: nodemanager
#    restart: always
#    environment:
#      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
#    env_file:
#      - ./hadoop.env
#
#  historyserver:
#    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
#    container_name: historyserver
#    restart: always
#    environment:
#      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
#    volumes:
#      - hadoop_historyserver:/hadoop/yarn/timeline
#    env_file:
#      - ./hadoop.env

  #############################################
  #               KAFKA                       #
  #############################################
#
  zookeeper-1:
    image: confluentinc/cp-zookeeper:7.3.1
    ports:
      - '32181:32181'
      - '2181:2181'
    environment:
      ZOOKEEPER_CLIENT_PORT: 32181
      ZOOKEEPER_TICK_TIME: 2000

  kafka-1:
    image: confluentinc/cp-kafka:7.3.1
    ports:
      - '9092:9092'
    depends_on:
      - zookeeper-1
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:32181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-1:29092,EXTERNAL://localhost:9092
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: 'false'


  kafka-2:
    image: confluentinc/cp-kafka:7.3.1
    ports:
      - '9093:9093'
    depends_on:
      - zookeeper-1
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:32181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-2:29093,EXTERNAL://localhost:9093
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: 'false'


  kafka-3:
    image: confluentinc/cp-kafka:7.3.1
    ports:
      - '9094:9094'
    depends_on:
      - zookeeper-1
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:32181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-3:29094,EXTERNAL://localhost:9094
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: 'false'

  kafdrop:
    image: obsidiandynamics/kafdrop:latest
    #    networks:
    #      - broker-kafka
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
    ports:
      - 19000:9000
    environment:
      KAFKA_BROKERCONNECT: kafka-1:29092

  zoonavigator:
    image:  elkozmon/zoonavigator:latest
    ports:
      - 19001:9000
    environment:
      HTTP_PORT: 9000

  #############################################
  #               MONITORING                  #
  #############################################

  prometheus:
    image: prom/prometheus:v2.47.0
    ports:
      - "19002:9090"
    extra_hosts:
      - "host.docker.internal:host-gateway" #crutial for prometheus to be able to access localhost
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml


  grafana:
    image: grafana/grafana:10.1.0
    ports:
      - "19003:3000"
    environment:
      - "GF_SECURITY_ADMIN_PASSWORD=grafana"

  #############################################
  #               SPARK                       #
  #############################################

  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    env_file:
      - ./hadoop.env
#    volumes:
#      - spark_vol:/spark # for zeppelin
  spark-worker-1:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    env_file:
      - ./hadoop.env
  spark-worker-2:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    env_file:
      - ./hadoop.env
  spark-history-server:
    image: bde2020/spark-history-server:3.3.0-hadoop3.3
    container_name: spark-history-server
    depends_on:
      - spark-master
    ports:
      - "18081:18081"
    volumes:
      - /tmp/spark-events-local:/tmp/spark-events
    env_file:
      - ./hadoop.env

  #############################################
  #               ZEPPELIN                    #
  #############################################
#  zeppelin:
#    image: apache/zeppelin:0.10.0
#    ports:
#      - "18082:8080"
#    volumes:
#      - spark_vol:/zeppelin/spark
#      - ./notebooks:/zeppelin/notebook
#    environment:
#      - "MASTER=spark://spark-master:7077"
#      - "SPARK_MASTER=spark://spark-master:7077"
#      - "SPARK_HOME=/zeppelin/spark"
#  hue:
#    image: bde2020/hdfs-filebrowser:3.11
#    ports:
#      - "18083:8088"
#    environment:
#      - NAMENODE_HOST=namenode

volumes:
#  spark_vol:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver: